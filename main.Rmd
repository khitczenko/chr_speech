---
title             : "Speech characteristics yield important clues about motor function: Speech variability in individuals at clinical high-risk for psychosis"
shorttitle        : "Speech Variability and Psychosis Risk"

author: 
  - name          : "Kasia Hitczenko"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "29 rue d'Ulm, Paris 75005, France"
    email         : "kasia.hitczenko@ens.psl.edu"
    
  - name          : "Yael Segal"
    affiliation   : "2"

  - name          : "Joseph Keshet"
    affiliation   : "2"

  - name          : "Matthew Goldrick"
    affiliation   : "3,4,5,8"

  - name          : "Vijay Mittal"
    affiliation   : "4,5,6,7,8,9"

affiliation:
  - id            : "1"
    institution   : "Laboratoire de Sciences Cognitives et Psycholinguistique, Département d’Études Cognitives, ENS, EHESS, CNRS, PSL University, Paris, France"
  - id            : "2"
    institution   : "Faculty of Electrical and Computer Engineering, Technion-Israel Institute of Technology, Haifa, Israel"
  - id            : "3"
    institution   : "Department of Linguistics, Northwestern University, Evanston, IL, USA"
  - id            : "4"
    institution   : "Department of Psychology, Northwestern University, Evanston, IL, USA"
  - id            : "5"
    institution   : "Cognitive Science Program, Northwestern University, Evanston, IL, USA"
  - id            : "6"
    institution   : "Department of Psychiatry, Northwestern University, Evanston, IL, USA"
  - id            : "7"
    institution   : "Medical Social Sciences, Northwestern University, Chicago, IL, USA"
  - id            : "8"
    institution   : "Institute for Policy Research, Northwestern University, Evanston, IL, USA"
  - id            : "9"
    institution   : "Institute for Innovations in in Developmental Sciences, Evanston/Chicago, IL, USA"

abstract: |

  Background and Hypothesis: Motor abnormalities are predictive of psychosis onset in individuals at clinical high risk (CHR) for psychosis and are tied to its progression. We hypothesize that these motor abnormalities also disrupt their speech production (a highly complex motor behavior) and predict CHR individuals will produce more variable speech pronunciations than healthy controls, and that this variability will relate to symptom severity, motor measures, and psychosis-risk calculator risk scores.

  Study Design: We measure variability in speech production (variability in consonants, vowels, speech rate, and pausing/timing) in N=58 CHR participants and N=67 healthy controls. Three different tasks are used to elicit speech: diadochokinetic speech (rapidly repeat syllables e.g., papapa…, pataka…), read speech, and spontaneously-generated speech. 
  
  Study Results: Individuals in the CHR group  produced more variable consonants and exhibited greater speech rate variability than healthy controls in two of the three speech tasks (diadochokinetic and read speech). While there were no significant correlations between speech measures and remotely-obtained motor measures, symptom severity, or conversion risk scores, these comparisons may be under-powered (in part due to challenges of remote data collection during the COVID-19 pandemic).
  
  Conclusion: This study provides a thorough and theory-driven first look at how speech production is affected in this at-risk population and speaks to the promise and challenges facing this approach moving forward.
  
keywords          : "clinical high-risk for psychosis; motor symptoms; speech articulation; speech acoustics"

bibliography      : "speech-in-chr-references.bib"
csl               : "american-medical-association-10th-edition.csl"

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_docx
---

```{r setup, include = FALSE}
library("papaja")
library("dplyr")
library("ggplot2")
library("ggpubr")
library("stringr")
r_refs("speech-in-chr-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

```{r output-functions}

mypval<-function(p) if(p < .001) "< .001" else paste("=", round(p,3))
myround <-function(val) round(val,2)

grpdiff_output <- function(test,var) {
  out <- paste0("$\\beta$ = ", myround(summary(test)$coefficients[var, "Estimate"]),
                ", s.e. = ", myround(summary(test)$coefficients[var, "Std. Error"]),
                ", z = ", myround(summary(test)$coefficients[var, "z value"]),
                ", p ", mypval(summary(test)$coefficients[var, "Pr(>|z|)"]))
  return(out)
}

corr_output <- function(test,var) {
  out <- paste0("$\\beta$ = ", myround(summary(test)$coefficients[var, "Estimate"]),
                ", s.e. = ", myround(summary(test)$coefficients[var, "Std. Error"]),
                ", t = ", myround(summary(test)$coefficients[var, "t value"]),
                ", p ", mypval(summary(test)$coefficients[var, "Pr(>|t|)"]))
  return(out)
}

get_grpdiff_p <- function(test,var) {
  out <- myround(summary(test)$coefficients[var, "Pr(>|z|)"])
  return(out)
}

extract_number <- function(str) {
  num <- 1
  if (grepl('(p=',str,fixed=TRUE)) {
    num <- as.numeric(strsplit(strsplit(str, "p=")[[1]][2],")")[[1]][1])
  }
  return(num)
}

```

Individuals with psychosis exhibit motor abnormalities (e.g., tremors, rigidity, dyskinesia, soft-signs) and recent work has suggested that these behaviors may also represent sensitive prognostic indicators during the prodromal period.[@cuesta_motor_2018; @van_harten_clinical_2017; @walther_motor_2012; @mittal_what_2017] In addition, motor signs can be objectively measured, in contrast to other symptom domains which are often subject to observer/rater bias.[@dean_handwriting_2013; @van_harten_clinical_2017] However, motor assessments frequently require significant expertise, as well as time-intensive analyses and/or cumbersome instrumentation.[@osborne_contingent_2020; @damme_detecting_2020; @dean_motion_2018; @bernard_cerebellar_2014; @van_harten_clinical_2017]  In this work, we explore one potential solution, examining the feasibility of using the physical properties of speech to measure motor abnormalities. Speech is a highly complex motor behavior, involving very fine-tuned movements that, when distorted in even subtle ways, can produce easily observable acoustic consequences (e.g., millimeter differences in placement/movement and millisecond differences in timing/coordination can substantially change the speech acoustics).[@kent_research_2000]

Because basal ganglia and cerebellar circuits modulate motor function and are also implicated in leading models of psychosis[@andreasen_cognitive_1998; @howes_dopamine_2009, @northoff_all_2021], there is good reason to believe that motor signs may be an early and sensitive biomarker.[@mittal_what_2017] Indeed, of the identified early vulnerability markers seen in children that develop adult psychosis, motor abnormalities may be the most common.[@erlenmeyer-kimling_attention_2000] For example, a myriad of motor behavior domains have been demonstrated to predict infants/children that ultimately develop adult schizophrenia including: delays in achieving motor milestones[@filatova_early_2017], neuromotor deficits and involuntary movements[@kindler_abnormal_2016], and neurological soft signs.[@rosso_childhood_2000]  One study comparing childhood video tapes of schizophrenia patients with videos of their healthy siblings, found that the pre-schizophrenia children showed a higher rate of motor abnormalities and delays. In a similar study, Schiffman and colleagues[@schiffman_childhood_2009] examined video-taped social interactions of 11-13 year old children who later developed schizophrenia and observed that a high occurrence of movement abnormalities distinguished the pre-schizophrenia children from matched controls. In adolescence, neuromaturational factors and environmental stressors can exacerbate underlying vulnerabilities in the motor and dopamine system[@howes_molecular_2007], leading to other outward manifestations in this age group, including spontaneous dyskinesias (i.e., spontaneous jerking and irregular ballistic movements).[@mittal_relations_2007] Indeed, among high-risk groups (i.e., those showing a low level of symptoms) these particular motor behaviors increase in frequency and severity as a function of development and increased disease burden, are associated with increased attenuated positive symptoms[@mittal_movement_2007; @mittal_longitudinal_2008] and strongly predict conversion to psychosis.[@mittal_movement_2007-1; @mittal_markers_2010; @dean_motor_2018]  As not all at-risk individuals go on to develop a psychotic disorder, this is highly relevant.[@mittal_as_2019]  Irrespective of medication (i.e., the motor abnormalities are present in neuroleptic naïve samples), these spontaneous jerking movements in the head, face, lips, and torso can continue to emerge during the adolescent prodromal period, until onset, when they remain a key clinical feature of the illness.[@pappa_spontaneous_2009] At least one cross-sectional study suggests that with advanced age, all patients with schizophrenia will eventually develop these behaviors.[@quinn_vulnerability_2001]   

Previous work has examined speech production in schizophrenia/psychosis.[@arevian_clinical_2020; @bernardini_associations_2016; @cohen_computerized_2008; @cohen_vocal_2016; @compton_aprosody_2018; @covington_phonetic_2012; @lozano-goupil_gesture-speech_2022; @martinez-sanchez_can_2015; @parola_voice_2020; @rapcan_acoustic_2010] This work has been promising, but results are mixed. A recent meta-analysis found three speech measures differentiated clinical and control groups, but only one (speech rate) was robust.[@parola_voice_2020] However, this prior work has generally not examined individuals at clinical high-risk (CHR), nor has it focused on motor abnormalities. It also has largely pursued a data-driven approach. Our work pursues a hypothesis-driven approach, studying acoustic measures that are predicted to be disrupted by motor abnormalities in speech produced by individuals at clinical-high-risk.

We hypothesize that disruptions to motor control will impact control over vocal articulators (e.g., tongue, lips), leading to more variable pronunciations in CHR participants when compared to healthy controls (HC), analogous to what has been observed in speech disorders.[@pascal_auzou_voice_2000; @goberman_acoustic_2002; @kent_toward_2003] Furthermore, if these speech measures reflect motor abnormalities, we would expect that increased variability in speech productions should relate to other measures of motor abnormalities (e.g., finger-tapping, as a test of convergent validity), worse symptom severity (as a test of clinical validity), and higher risk of conversion to psychosis (as a test of predictive validity). To systematically examine the conditions under which motor difficulties are observed, we elicit speech in highly-controlled samples that are specifically designed to measure motor difficulties (diadochokinetic speech), read speech, as well as more free-form, naturalistic speech which closely resembles everyday speech.

# Results

```{r, read-in-data}
# Read in data
ddk <- read.csv("../data/preprocessed-analysis-input-ddk.csv")
rp <- read.csv("../data/preprocessed-analysis-input-rp.csv")
pbj <- read.csv("../data/preprocessed-analysis-input-pbj.csv")
clinical <- read.csv('../data/participant-info-we-collected.xlsx - chr.csv')
clinical$Participant <- substr(clinical$Participant, 1, 4)
ddk <- merge(ddk, clinical, by.x = 'participant', by.y = 'Participant')
rp <- merge(rp, clinical, by.x = 'participant', by.y = 'Participant')
pbj <- merge(pbj, clinical, by.x = 'participant', by.y = 'Participant')
participant_list <- distinct(bind_rows(rp, ddk, pbj), participant)
demo <- merge(participant_list, clinical, by.x ='participant', by.y = 'Participant')

```

```{r ddk-stats}
ddk$part_grp <- factor(ddk$part_grp)
vot_amr.stats <- glm(part_grp ~ log_coeffvar_vot_duration + log(avg_ddk_rate), data = subset(ddk, subtask == 'amr'), family = 'binomial')
vot_smr.stats <- glm(part_grp ~ log_coeffvar_vot_duration + log(avg_ddk_rate), data = subset(ddk, subtask == 'smr'), family = 'binomial')
ddkrate_amr.stats <- glm(part_grp ~ log_coeffvar_ddk_rate, data = subset(ddk, subtask == 'amr'), family = 'binomial')
ddkrate_smr.stats <- glm(part_grp ~ log_coeffvar_ddk_rate, data = subset(ddk, subtask == 'smr'), family = 'binomial')
```

```{r, read-stats}

# Group differences
rp$part_grp <- factor(rp$part_grp)
vot_rp.stats <- glm(part_grp ~ log_coeffvar_vot_voiceless_duration + log_avg_local_speech_rate, data = rp, family = 'binomial')
ddkrate_rp.stats <- glm(part_grp ~ log_coeffvar_local_speech_rate, data = rp, family = 'binomial')

# Correlations
rp$log_FingerTapping_SCTAP_NonCV <- log(rp$FingerTapping_SCTAP_NonCV)
rp$log_FingerTapping_SCTAP_NonCV[is.infinite(rp$log_FingerTapping_SCTAP_NonCV)] <- NA
rp$log_FingerTapping_SCTAP_DomCV <- log(rp$FingerTapping_SCTAP_DomCV)
rp$log_FingerTapping_SCTAP_DomCV[is.infinite(rp$log_FingerTapping_SCTAP_DomCV)] <- NA
rp.lsr_nondomfingercv.stats <- lm(log_FingerTapping_SCTAP_NonCV ~ log_coeffvar_local_speech_rate, data = subset(rp, part_grp == 'Clinical High-Risk' & !is.na(FingerTapping_SCTAP)))
rp.lsr_domfingercv.stats <- lm(log_FingerTapping_SCTAP_DomCV ~ log_coeffvar_local_speech_rate, data = subset(rp, part_grp == 'Clinical High-Risk' & !is.na(FingerTapping_SCTAP)))

```

```{r spontaneous-stats}
pbj$part_grp <- factor(pbj$part_grp)
vot_pbj.stats <- glm(part_grp ~ log_coeffvar_vot_voiceless_duration + log_avg_local_speech_rate, data = pbj, family = 'binomial')
ddkrate_pbj.stats <- glm(part_grp ~ log_coeffvar_local_speech_rate, data = pbj, family = 'binomial')
```

```{r, additional-stats-for-table}

# DDK
voweldur_amr.stats <- glm(part_grp ~ log_coeffvar_vowel_duration + log(avg_ddk_rate), data = subset(ddk, subtask == 'amr'), family = 'binomial')
voweldur_smr.stats <- glm(part_grp ~ log_coeffvar_vowel_duration + log(avg_ddk_rate), data = subset(ddk, subtask == 'smr'), family = 'binomial')
voweldisp_amr.stats <- glm(part_grp ~ log(formant_dispersion.20), data = subset(ddk, subtask == 'amr'), family = 'binomial')
voweldisp_smr.stats <- glm(part_grp ~ log(formant_dispersion.20), data = subset(ddk, subtask == 'smr'), family = 'binomial')
voweldispdelta_amr.stats <- glm(part_grp ~ formant_delta_var, data = subset(ddk, subtask == 'amr'), family = 'binomial')
voweldispdelta_smr.stats <- glm(part_grp ~ formant_delta_var, data = subset(ddk, subtask == 'smr'), family = 'binomial')
sylldur_amr.stats <- glm(part_grp ~ log(coeffvar_syll_duration) + log(avg_ddk_rate), data = subset(ddk, subtask == 'amr'), family = 'binomial')
sylldur_smr.stats <- glm(part_grp ~ log(coeffvar_syll_duration) + log(avg_ddk_rate), data = subset(ddk, subtask == 'smr'), family = 'binomial')
intersylldur_amr.stats <- glm(part_grp ~ log(coeffvar_intersyll_duration) + log(avg_ddk_rate), data = subset(ddk, subtask == 'amr'), family = 'binomial')
intersylldur_smr.stats <- glm(part_grp ~ log(coeffvar_intersyll_duration) + log(avg_ddk_rate), data = subset(ddk, subtask == 'smr'), family = 'binomial')

# RP
voiced_vot_rp.stats <- glm(part_grp ~ log_coeffvar_vot_voiced_duration + log_avg_local_speech_rate, data = rp, family = 'binomial')
voweldur_rp.stats <- glm(part_grp ~ log_coeffvar_vowel_duration + log_avg_local_speech_rate, data = rp, family = 'binomial')
voweldisp_rp.stats <- glm(part_grp ~ log(formant_dispersion.20), data = rp, family = 'binomial')
voweldispdelta_rp.stats <- glm(part_grp ~ formant_delta_var, data = rp, family = 'binomial')
vowelphoncomp_rp.stats <- glm(part_grp ~ log_formant_phonetic_competition, data = rp, family = 'binomial')
pauses_rp.stats <- glm(part_grp ~ log_n_pauses_per_word, data = rp, family = 'binomial')

# PBJ
voiced_vot_pbj.stats <- glm(part_grp ~ log_coeffvar_vot_voiced_duration + log_avg_local_speech_rate, data = subset(pbj, !is.infinite(log_coeffvar_vot_voiced_duration)), family = 'binomial')
voweldur_pbj.stats <- glm(part_grp ~ log_coeffvar_vowel_duration + log_avg_local_speech_rate, data = pbj, family = 'binomial')
voweldisp_pbj.stats <- glm(part_grp ~ log(formant_dispersion.20), data = pbj, family = 'binomial')
voweldispdelta_pbj.stats <- glm(part_grp ~ formant_delta_var, data = pbj, family = 'binomial')
vowelphoncomp_pbj.stats <- glm(part_grp ~ log_formant_phonetic_competition, data = subset(pbj, !is.na(log_formant_phonetic_competition)), family = 'binomial')
pauses_pbj.stats <- glm(part_grp ~ log_n_pauses_per_word, data = pbj, family = 'binomial')

```

We present results by speech task. We focused on acoustic speech measures that have been extremely well-studied and can be reliably measured automatically (which allows us to study greater quantities of speech). The main text focuses on (i) variability in the audible duration (voice-onset-time) of voiceless (in English: p,t,k) and voiced (in English, b,d,g) stop consonants, (ii) variability in vowel durations, and (iii) variability in speech rates. We discuss the remaining speech measures we studied (including variability in vowel formants and variability in pausing/timing)[@sichlinger_clinical_2019; @stanislawski_negative_2021; @hillenbrand_acoustic_1995; @mccloy_talker_2015; @xie_lifg_2018; @niziolek_assessing_2018] in Table \@ref(tab:speech-measures-table) and SM-1.3.

N.B.: One CHR participant was identified as in-remission and another participant had a 7-months’ gap between their clinical interview and speech tasks. SM-2.7 includes analyses without these two participants; the results are qualitatively similar to the analyses of the full dataset reported below.

```{r, speech-measures-table}

library(flextable)
library(officer)

amr_summary <- c("Consonant Production Measures",
             paste0("- CoV of voiceless stop VOTs (p=", get_grpdiff_p(vot_amr.stats, "log_coeffvar_vot_duration"), ")"),
             "",
             "Speech Rate Measures",
             paste0("- CoV of speech rate (p=", get_grpdiff_p(ddkrate_amr.stats, "log_coeffvar_ddk_rate"),")"),
             "Vowel Production Measures",
             paste0("- CoV of vowel durations (p=", get_grpdiff_p(voweldur_amr.stats, "log_coeffvar_vowel_duration"), ")"),
             paste0("- Formant dispersion 20% (p=", get_grpdiff_p(voweldisp_amr.stats, "log(formant_dispersion.20)"), ")"),
             paste0("- Change in formant dispersion 20-50% (p=", get_grpdiff_p(voweldispdelta_amr.stats, "formant_delta_var"), ")"),
             "",
             "Timing/Pausing Measures",
             paste0("- CoV of syllable durations (p=", get_grpdiff_p(sylldur_amr.stats, "log(coeffvar_syll_duration)"), ")"),
             paste0("- CoV of intersyllable durations (p=", get_grpdiff_p(intersylldur_amr.stats, "log(coeffvar_intersyll_duration)"), ")"))

smr_summary <- c("Consonant Production Measures",
             paste0("- CoV of voiceless stop VOTs (p=", get_grpdiff_p(vot_smr.stats, "log_coeffvar_vot_duration"), ")"),
             "",
             "Speech Rate Measures",
             paste0("- CoV of speech rate (p=", get_grpdiff_p(ddkrate_smr.stats, "log_coeffvar_ddk_rate"),")"),
             "Vowel Production Measures",
             paste0("- CoV of vowel durations (p=", get_grpdiff_p(voweldur_smr.stats, "log_coeffvar_vowel_duration"), ")"),
             paste0("- Formant dispersion 20% (p=", get_grpdiff_p(voweldisp_smr.stats, "log(formant_dispersion.20)"), ")"),
             paste0("- Change in formant dispersion 20-50% (p=", get_grpdiff_p(voweldispdelta_smr.stats, "formant_delta_var"), ")"),
             "",
             "Timing/Pausing Measures",
             paste0("- CoV of syllable durations (p=", get_grpdiff_p(sylldur_smr.stats, "log(coeffvar_syll_duration)"), ")"),
             paste0("- CoV of intersyllable durations (p=", get_grpdiff_p(intersylldur_smr.stats, "log(coeffvar_intersyll_duration)"), ")"))

rp_summary <- c("Consonant Production Measures",
             paste0("- CoV of voiceless stop VOTs (p=", get_grpdiff_p(vot_rp.stats, "log_coeffvar_vot_voiceless_duration"), ")"),
             paste0("- CoV of voiced stop VOTs (p=", get_grpdiff_p(voiced_vot_rp.stats, "log_coeffvar_vot_voiced_duration"), ")"),
             "Speech Rate Measures",
             paste0("- CoV of speech rate (p=", get_grpdiff_p(ddkrate_rp.stats, "log_coeffvar_local_speech_rate"),")"),
             "Vowel Production Measures",
             paste0("- CoV of vowel durations (p=", get_grpdiff_p(voweldur_rp.stats, "log_coeffvar_vowel_duration"), ")"),
             paste0("- Formant dispersion 20% (p=", get_grpdiff_p(voweldisp_rp.stats, "log(formant_dispersion.20)"), ")"),
             paste0("- Change in formant dispersion 20-50% (p=", get_grpdiff_p(voweldispdelta_rp.stats, "formant_delta_var"), ")"),
             paste0("- Overlap between vowel categories (p=", get_grpdiff_p(vowelphoncomp_rp.stats, "log_formant_phonetic_competition"), ")"),
             "Timing/Pausing Measures",
             paste0("- Number of pauses (p=", get_grpdiff_p(pauses_rp.stats, "log_n_pauses_per_word"), ")"),
             "")

pbj_summary <- c("Consonant Production Measures",
             paste0("- CoV of voiceless stop VOTs (p=", get_grpdiff_p(vot_pbj.stats, "log_coeffvar_vot_voiceless_duration"), ")"),
             paste0("- CoV of voiced stop VOTs (p=", get_grpdiff_p(voiced_vot_pbj.stats, "log_coeffvar_vot_voiced_duration"), ")"),
             "Speech Rate Measures",
             paste0("- CoV of speech rate (p=", get_grpdiff_p(ddkrate_pbj.stats, "log_coeffvar_local_speech_rate"),")"),
             "Vowel Production Measures",
             paste0("- CoV of vowel durations (p=", get_grpdiff_p(voweldur_pbj.stats, "log_coeffvar_vowel_duration"), ")"),
             paste0("- Formant dispersion 20% (p=", get_grpdiff_p(voweldisp_pbj.stats, "log(formant_dispersion.20)"), ")"),
             paste0("- Change in formant dispersion 20-50% (p=", get_grpdiff_p(voweldispdelta_pbj.stats, "formant_delta_var"), ")"),
             paste0("- Overlap between vowel categories (p=", get_grpdiff_p(vowelphoncomp_pbj.stats, "log_formant_phonetic_competition"), ")"),
             "Timing/Pausing Measures",
             paste0("- Number of pauses (p=", get_grpdiff_p(pauses_pbj.stats, "log_n_pauses_per_word"), ")"),
             "")

summary_measures <- data.frame(
  "Diadochokinetic AMR (papapa)" = amr_summary,
  "Diadochokinetic SMR (pataka)" = smr_summary,
  "Read" = rp_summary,
  "Spontaneous" = pbj_summary
)

sumtab <- flextable(summary_measures)
sumtab <- hline(sumtab, i=c(1,3,4,5,6,10,11), j = NULL, border = fp_border(color = "black"), part =  "body")
sumtab <- merge_h(sumtab, i=c(1,4,6,11))
sumtab <- align(sumtab, i=c(1,4,6,11), align = "center", part = "body")
sumtab <- width(sumtab, width = 1.75, unit = "in")

for (n in 1:length(colnames(summary_measures))) {
  sig <- c()
  trend <- c()
  for (m in 1:nrow(summary_measures)) {
    if (extract_number(summary_measures[m,colnames(summary_measures)[n]]) < 0.05) {
      sig <- c(sig, m)
    } else if (extract_number(summary_measures[m,colnames(summary_measures)[n]]) < 0.10) {
      trend <- c(trend, m)
    }
  }
  if (length(sig) > 0) {sumtab <- bold(sumtab, i=sig, j=n, bold = TRUE)}
  if (length(trend) > 0) {sumtab <- italic(sumtab, i=trend, j=n, italic = TRUE)}
}

sumtab <- set_caption(sumtab, caption = "Summary of the studied speech measures. Speech measures are bolded if they show a significant CHR vs. HC group difference and italicized if just above significance (corresponding p-values shown). CoV: coefficient of variation; VOT: voice-onset-time.")
sumtab

```

## Diadochokinetic Speech Tasks

Participants first completed a diadochokinetic speech task, in which they produced particular syllable types as quickly and as accurately as possible.[@ackermann_oral_1995; @fletcher_time-by-count_1972] This task consisted of two trial types that we analyze separately: Alternating Motion Rate (AMR) trials, in which participants repeated a single target syllable 15 times (e.g., pa-pa-pa..., ta-ta-ta..., ka-ka-ka...) and Sequential Motion Rate (SMR) trials, in which they repeated sequences of three syllables 10 times (e.g., pa-ta-ka..., ka-ta-pa...).

Out of the seven speech measures we studied (Table \@ref(tab:speech-measures-table)), we found evidence that variability in voiceless stop consonant production predicted CHR vs. HC status (in other words, showed CHR vs. HC group differences) near-significantly in AMR trials (`r grpdiff_output(vot_amr.stats, "log_coeffvar_vot_duration")`; Figure \@ref(fig:grp-diff-plots)A) and significantly in SMR trials (`r grpdiff_output(vot_smr.stats, "log_coeffvar_vot_duration")`; Figure \@ref(fig:grp-diff-plots)B). Speech rate variability predicted CHR vs. HC status in both AMR and SMR trials (AMR: `r grpdiff_output(ddkrate_amr.stats, "log_coeffvar_ddk_rate")`; SMR: `r grpdiff_output(ddkrate_smr.stats, "log_coeffvar_ddk_rate")`; with one exception, all other speech measures showed no significant effects). However, these two measures did not correlate with SIPS scores, finger-tapping, or risk scores (results in SM-2.1).

(ref:read-corr-plots-caption) We observe a significant positive relationship between variability in speech rate and variability in finger-tapping rates in the non-dominant hand (left plot), but not the dominant hand (right plot). Each point represents one participant; the line of best-fit is shown, with shaded regions showing standard errors of the regression fit.

```{r individual-grp-diff-plots, fig.width = 4, fig.height = 7}

vot_amr <- ggplot(data=subset(ddk, subtask == 'amr'), aes(y=log_coeffvar_vot_duration, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylab("Voiceless VOT\nCoefficient of Variation (Log)") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

ddkrate_amr <- ggplot(data=subset(ddk, subtask == 'amr'), aes(y=log_coeffvar_ddk_rate, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylab("Speech Rate\nCoefficient of Variation (Log)") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

vot_smr <- ggplot(data=subset(ddk, subtask == 'smr'), aes(y=log_coeffvar_vot_duration, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylab("Voiceless VOT\nCoefficient of Variation (Log)") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

ddkrate_smr <- ggplot(data=subset(ddk, subtask == 'smr'), aes(y=log_coeffvar_ddk_rate, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylab("Speech Rate\nCoefficient of Variation (Log)") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

vot_rp <- ggplot(data=rp, aes(y=log_coeffvar_vot_voiceless_duration, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylab("Voiceless VOT\nCoefficient of Variation (Log)") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

ddkrate_rp <- ggplot(data=rp, aes(y=log_coeffvar_local_speech_rate, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylab("Speech Rate\nCoefficient of Variation (Log)") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

vot_pbj <- ggplot(data=pbj, aes(y=log_coeffvar_vot_voiceless_duration, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylab("Voiceless VOT\nCoefficient of Variation (Log)") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

ddkrate_pbj <- ggplot(data=pbj, aes(y=log_coeffvar_local_speech_rate, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylab("Speech Rate\nCoefficient of Variation (Log)") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

```

```{r intermediate-grp-diff-plots, fig.width = 8, fig.height = 3}
amr_diffplot <- ggarrange(vot_amr, ddkrate_amr, ncol = 2)
smr_diffplot <- ggarrange(vot_smr, ddkrate_smr, ncol = 2)
rp_diffplot <- ggarrange(vot_rp, ddkrate_rp, ncol = 2)
pbj_diffplot <- ggarrange(vot_pbj, ddkrate_pbj, ncol = 2)
```

(ref:diff-plots-caption) CHR individuals produce more variable consonants (left plot in each row) and speech rates (right plot in each row) compared to controls in (A) Diadochokinetic-AMR, (B) Diadochokinetic-SMR, and (C) Read speech, but not (D) Spontaneous speech. Each black dot is one participant; the white dot is the average across participants.

```{r grp-diff-plots, fig.width = 8, fig.height = 10, fig.cap = "(ref:diff-plots-caption)"}
merged_diffplots <- ggarrange(labels = c("A", "B", "C", "D"), ncol = 1, nrow = 4,
  annotate_figure(amr_diffplot, text_grob("Diadochokinetic AMR (papapa/tatata/kakaka) Results", color = "black", face = "bold", size = 12)),
  annotate_figure(smr_diffplot, text_grob("Diadochokinetic SMR (pataka/katapa) Results", color = "black", face = "bold", size = 12)), 
  annotate_figure(rp_diffplot, text_grob("Read Speech Results", color = "black", face = "bold", size = 12)), 
  annotate_figure(pbj_diffplot, text_grob("Spontaneous Procedural Description Results", color = "black", face = "bold", size = 12)))
merged_diffplots
```

## Read Speech
Participants then read a standardized passage aloud at a comfortable pace (full text in Supplementary Materials: SM-1.1). As in the Diadochokinetic speech task, we found that variability in voiceless stop consonant duration (`r grpdiff_output(vot_rp.stats, "log_coeffvar_vot_voiceless_duration")`) and variability in speech rate (`r grpdiff_output(ddkrate_rp.stats, "log_coeffvar_local_speech_rate")`) predicted CHR vs. HC group status (Figure \@ref(fig:grp-diff-plots)C; all other speech measures showed no significant effects). Variation in speech rate (but not consonant production) was significantly correlated with another motor measure, variability in finger-tapping rate in the non-dominant hand (`r corr_output(rp.lsr_nondomfingercv.stats, "log_coeffvar_local_speech_rate")`), but not in the dominant hand (`r corr_output(rp.lsr_domfingercv.stats, "log_coeffvar_local_speech_rate")`; Figure \@ref(fig:read-corr-plots)). However, these measures did not correlate with clinical or risk measures.

```{r, read-corr-plots, fig.cap = "(ref:read-corr-plots-caption)", fig.width = 8, fig.height = 3.2}

p_non <- ggplot(subset(rp, part_grp == 'Clinical High-Risk' & !is.na(log_FingerTapping_SCTAP_NonCV)), aes(x=log_coeffvar_local_speech_rate, y=log_FingerTapping_SCTAP_NonCV)) + geom_point() + xlab('Speech Rate\nCoefficient of Variation (Log)') + ylab('Finger Tapping (Non-Dominant Hand)\nCoefficient of Variation (Log)') + geom_smooth(method = "lm", se = TRUE)
p_dom <- ggplot(subset(rp, part_grp == 'Clinical High-Risk' & !is.na(log_FingerTapping_SCTAP_DomCV)), aes(x=log_coeffvar_local_speech_rate, y=log_FingerTapping_SCTAP_DomCV)) + geom_point() + xlab('Speech Rate\nCoefficient of Variation (Log)') + ylab('Finger Tapping (Dominant Hand)\nCoefficient of Variation (Log)') + geom_smooth(method = "lm", se = TRUE)

ftcorr <- ggarrange(p_dom, p_non, ncol = 2)
ftcorr

```

## Spontaneous Speech
Finally, we elicited spontaneous speech, by asking participants to describe how to make a peanut butter and jelly sandwich for ~2 minutes. In contrast to the Diadochokinetic and Read speech samples, we found that none of the speech measures significantly predicted group status in spontaneous speech (Figure \@ref(fig:grp-diff-plots)D), including the two measures impacted in the previous tasks: variability in voiceless consonant duration (`r grpdiff_output(vot_pbj.stats, "log_coeffvar_vot_voiceless_duration")`) and variability in speech rate (`r grpdiff_output(ddkrate_pbj.stats, "log_coeffvar_local_speech_rate")`).

```{r, inperson-vs-remote-individual-plots}

vot_amr_inp <- ggplot(data=subset(ddk, subtask == 'amr' & Test.Type == 'InPerson'), aes(y=log_coeffvar_vot_duration, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylim(-2, -0.5) + ylab("Voiceless VOT\nCoefficient of Variation (Log)") + ggtitle("In Person Testing") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

vot_amr_rem <- ggplot(data=subset(ddk, subtask == 'amr' & Test.Type == 'Remote'), aes(y=log_coeffvar_vot_duration, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylim(-2, -0.5) + ylab("Voiceless VOT\nCoefficient of Variation (Log)") + ggtitle("Remote Testing") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

ddkrate_amr_inp <- ggplot(data=subset(ddk, subtask == 'amr' & Test.Type == 'InPerson'), aes(y=log_coeffvar_ddk_rate, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylim(-4.6, -1.45) + ylab("Speech Rate\nCoefficient of Variation (Log)") + ggtitle("In Person Testing") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

ddkrate_amr_rem <- ggplot(data=subset(ddk, subtask == 'amr' & Test.Type == 'Remote'), aes(y=log_coeffvar_ddk_rate, x=part_grp, fill=part_grp)) + geom_boxplot(outlier.color=NA) + geom_jitter(width=0.15) + ylim(-4.6, -1.45) + ylab("Speech Rate\nCoefficient of Variation (Log)") + ggtitle("Remote Testing") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.x = element_blank(), axis.text.x = element_text(size=11.5), axis.title.y = element_text(size=12)) + stat_summary(fun=mean, geom="point", shape=20, size=6, color="white", fill="white")

vot_amr_inp_rem <- ggarrange(vot_amr_inp, vot_amr_rem, align = "hv", ncol = 2)
ddkrate_amr_inp_rem <- ggarrange(ddkrate_amr_inp, ddkrate_amr_rem, ncol = 2)

```

(ref:inperson-remote-plots-caption) (A) Group differences in consonant variability only emerged in in-person (left plot), not remote (right plot) testing conditions. (B) Group differences in speech rate variability were qualitatively similar across the in-person and remote subgroups (example plots from Diadochokinetic-AMR speech). Each black dot represents one participant; the white dot represents the average value across participants.

```{r, inperson-remote-plots, fig.cap = "(ref:inperson-remote-plots-caption)", fig.width = 7.5, fig.height = 6}

inp_vs_rem <- ggarrange(labels = c("A", "B"), ncol = 1, nrow = 2,
  annotate_figure(vot_amr_inp_rem, text_grob("Voiceless VOT Results\nDiadochokinetic-AMR (papapa/tatata/kakaka) Subtask", color = "black", face = "bold", size = 12)),
  annotate_figure(ddkrate_amr_inp_rem, text_grob("Speech Rate Results\nDiadochokinetic-AMR (papapa/tatata/kakaka) Subtask", color = "black", face = "bold", size = 12)))
inp_vs_rem

```

## In-Person vs. Remote results

Because data collection occurred between 2019-2022, our study had to be adapted to the remote format partway through due to the COVID-19 pandemic (see Methods for details). In post-hoc analyses, we tested whether results differed between participants tested in-person (N=`r nrow(subset(demo, trimws(Test.Type) == 'InPerson'))`) vs. remotely (N=`r nrow(subset(demo, trimws(Test.Type) == 'Remote'))`), focusing on the measures and tasks that showed group differences in our primary analyses (Figures \@ref(fig:inperson-remote-plots) and S8-S9). Full results are presented in SM-2.4, but we generally observed that group differences in consonant variability were less stark in the remote subgroup relative to the in-person group. This seemed to be driven by greater variability in the remotely-recorded control group relative to the in-person control group. For speech rate, however, the in-person and remote subgroups showed qualitatively similar patterns, except in the Diadochokinetic-SMR subtask, where we again observed a reduction in CHR vs. HC group differences when tested remotely.

## Unpacking why we did not see relationship with clinical/motor symptoms
Contrary to our predictions, we found that the speech measures that differentiated the CHR vs. HC groups did not correlate with motor, clinical, or risk measures. We ran several additional exploratory analyses in an attempt to unpack this surprising finding.

Past work has shown that some linguistic measures are highly correlated with sociodemographic factors.[@hitczenko_automated_2021; @hitczenko_racial_2022; @palaniyappan_more_2021] To verify this was not the case for the speech measures we studied, we ran regressions predicting demographic factors (age, sex, race, native language) from the speech measures that significantly differentiated the high-risk and healthy control groups. We found no significant relationships, suggesting that the observed group differences were not accounted for by demographic factors (see SM-2.5).

We then tested whether the non-speech (motor/clinical/risk) measures correlated with one another as we would expect based on previous work.[@damme_detecting_2020; @damme_sensorimotor_2021] They did not. In our sample, individuals with greater motor abnormalities (measured by finger-tapping) did not have worse overall symptoms or higher risk of conversion scores (see SM-2.6). This suggests we did not have sufficient power to detect motor abnormalities.

# Discussion

We find evidence that individuals at clinical high-risk for psychosis produce more variable speech - in particular, more variable consonants and speech rates - than healthy controls in two of the three speech types we study. However, contrary to predictions, we found that increased speech variability did not correlate with non-speech motor measures, symptom severity, or conversion risk scores. Follow-up analyses suggest that these comparisons may have been underpowered and, in particular, affected by a midway shift from in-person to remote testing. This theory-driven analysis provides a thorough first look at how speech production is affected in the CHR population and speaks to the promise and challenges facing this approach to measuring motor symptoms.

## Not all aspects of speech are affected and not in all contexts

Our findings converge with Parola et al.’s[@parola_voice_2020], which found that other aspects of speech rate were the strongest acoustic factor in a meta-analysis differentiating groups (n.b. they did not study voice-onset-time or speech rate variability). This stands in notable contrast to past findings in the field, which generally showed mixed results across studies (i.e., the particular speech measures that differed between groups differed depending on the study and speech samples; see discussion in Hitczenko et al.[@hitczenko_understanding_2021]). We believe this consistency across speech tasks and convergence with past studies reflects the benefits of adopting a theory-driven approach when studying highly variable speech signals.

That being said, most of the speech measures did not show group differences. In particular, we failed to find effects of variability of voiced consonant production (b,d,g), which likely reflects motor control demands. Specifically, English voiceless consonants involve more motor coordinating/timing than voiced consonants, as the vocal folds need to be suppressed for a specific amount of time.[@bortolini_word-initial_1995; @kewley-port_early_1974; @kong_fine-grained_2007; @kessinger_effects_1997; @gavino_consequences_2022; @goldrick_effects_2013] We also failed to find the expected effect for vowels. This is less expected, but one possibility is that it may reflect the more precise articulatory and timing requirements for stop consonants, which are overall much shorter than vowels.

In addition to variable results across measures, group differences only appeared in some of the speech tasks: Diadochokinetic-AMR, Diadochokinetic-SMR, and read speech, but not spontaneous speech. This may reflect the degree to which different tasks present challenges to speech articulation. Diadochokinetic speech involves unnatural rapid repetition of syllables, while the passage participants read includes many low frequency words (e.g., Aristotle, bow, refraction). Indeed, qualitatively, participants often remarked on the difficult aspects of these tasks, or produced disfluent speech. These sorts of targeted, more challenging speech tasks may be necessary for detecting the impact of motor disruptions on speech articulation. Another possibility is that this simply reflects statistical power; the spontaneous task was shorter, and the content was more variable, which may have washed out subtle differences between groups.

Finally, there was some evidence of differences between in-person and remote participants. Healthy control individuals generally had more variable speech measures when tested remotely vs. in-person, reducing our ability to detect group differences. There has been substantial recent interest in developing remote options for all manner of clinical assessment (e.g., to reach individuals who are medically underserved[@sharp_use_2011]), but this result reveals that these approaches need to be carefully developed and validated. In the case of speech measures specifically, our results likely reflect issues in an analysis pipeline that was developed to analyze speech recorded in controlled laboratory conditions. More broadly, expanding access to such assessments requires developing analysis methods that are robust to variation in testing and recording conditions.

## Speech measures did not correlate with motor, clinical, or conversion risk variables

While the observed group differences provide converging support that speech/motor symptoms are observed very early in the progression of psychosis, the biggest challenge facing these speech measures is that they mostly did not correlate with clinical/motor/risk variables. This could reflect insufficient power. We had non-speech motor symptoms for ~50 CHR participants, which would only let us detect effect sizes of 0.34 or higher. Exploratory analyses suggest that our particular sample and measures may have been insufficient to detect the typical clinical-high-risk motor profile, which would also weaken our ability to detect speech-motor relationships. Finally, we had to adapt our data collection procedure partway through to adhere to pandemic-related restrictions, including shortening the finger-tapping task and collecting speech samples remotely (participants were mailed audio recorders to their homes). While these changes were unavoidable, they reduced our power (e.g., by reducing the number of finger-tapping observations) and may have affected reliability, by introducing noise into our measures. We provided extensive guidelines, but ultimately had limited control over the participants’ environment (e.g., how noisy it was) and equipment (e.g., keyboard). Beyond practical task differences, the pandemic also may have had a substantial effect on individuals’ mental health, further increasing variability.[@brown_potential_2020; @druss_addressing_2020]

Nonetheless, even though the speech measures did not correlate with clinical/motor variables, the fact that they differed by clinical status (CHR vs HC), which is assigned based on clinical interview, means that, on some level, these measures must be related to symptomatology. In addition, the speech differences we observe could reflect motor abnormalities that are not captured by previously-developed measures (e.g., finger-tapping). In this case, we would not expect to see a correlation between the speech measures and previously-developed measures, but the speech measures would nonetheless be clinically informative. In sum, these differences are worthy of further investigation to understand what these speech measures reflect and how they can help researchers/clinicians.

## Recommendations for future approaches
Based on our results, future studies should prioritize difficult speech tasks that specifically target the speech feature of interest (e.g., diadochokinetic speech involving both voiceless/voiced consonants and a variety of vowels; sustained phonation tasks). An additional benefit of the more targeted measures is that they are easily transferable across other languages (many languages have the diadochokinetic speech syllables), which will be critical for establishing the validity and generalizability of these measures across populations.[@parola_speech_2022]).

In addition, the clinical-high-risk group is heterogeneous and future work should identify and study well-motivated subgroups.[@dean_motor_2018; @gupta_deconstructing_2021; @mittal_covid-19_2021] This is important because speech is affected by motor abilities, but also many other factors. For example, past work has often studied speech as a window into negative symptoms. Researchers adopting that approach predict that individuals with psychosis will exhibit *less* variability, while motor deficits should result in *more* variability. Competing effects of this sort could obscure a clear relationship between speech and symptoms. To address this issue, future work could collect a larger clinical-high-risk sample and identify a subgroup that primarily shows negative symptoms vs. a subgroup that primarily shows motor symptoms, and test whether they show different speech profiles in accordance with their different symptom profiles.

Overall, however, while many questions remain, the present work provides a solid foundation for future work investigating the insights that speech production can provide for understanding the mechanisms impacted in individuals at clinical-high-risk for psychosis.

# Methods

## Participants
N=`r length(demo$participant)` participants (N=`r nrow(subset(demo, Group == 'chr'))` CHR; N=`r nrow(subset(demo, Group == 'hc'))` HC) provided speech data, though not everybody provided data for all three tasks. The data of two CHR participants were excluded: one dropped out of the study and the other was later determined to have been erroneously classified as high-risk. This left N=`r nrow(ddk)/2` (N=`r nrow(subset(ddk, Group == 'chr'))/2` CHR; N=`r nrow(subset(ddk, Group == 'hc'))/2` HC) diadochokinetic speech samples, N=`r nrow(rp)` (N=`r nrow(subset(rp, Group == 'chr'))` CHR; N=`r nrow(subset(rp, Group == 'hc'))` HC) read speech samples, and N=`r nrow(pbj)` (N=`r nrow(subset(pbj, Group == 'chr'))` CHR; N=`r nrow(subset(pbj, Group == 'hc'))` HC) spontaneous speech samples. The Structured Interview for Prodromal Syndromes (SIPS) was used to determine the clinical status of each participant (CHR vs. HC).[@miller_symptom_1999] See Table \@ref(tab:demo-table) for participant demographics.

(ref:demo-table-caption) Summary of participant demographic information.

```{r demo-table}

rownames = c("N", "Sex (% Female)", "Age (SD)", "Race", "Ethnicity", "First Language")
colnames = c("Clinical High-Risk (CHR)", "Healthy Controls (HC)")
demo_table <- matrix(rep(NA, 12), nrow = 6, ncol = 2, byrow = TRUE, dimnames = list(rownames, colnames))
demo_table["N","Clinical High-Risk (CHR)"] <- paste0(nrow(subset(demo, Group == 'chr')), 
                                                     " (In-Person: ", nrow(subset(demo, Group == 'chr' & trimws(Test.Type) == 'InPerson')), 
                                                     "; Remote: ", nrow(subset(demo, Group == 'chr' & trimws(Test.Type) == 'Remote')), ")")
demo_table["N","Healthy Controls (HC)"] <- paste0(nrow(subset(demo, Group == 'hc')), 
                                                     " (In-Person: ", nrow(subset(demo, Group == 'hc' & trimws(Test.Type) == 'InPerson')), 
                                                     "; Remote: ", nrow(subset(demo, Group == 'hc' & trimws(Test.Type) == 'Remote')), ")")
demo_table["Sex (% Female)", "Clinical High-Risk (CHR)"] <- paste0(round(prop.table(table(subset(demo, Group == 'chr')$Demo_Sex))["1"]*100, 1), '%')
demo_table["Sex (% Female)", "Healthy Controls (HC)"] <- paste0(round(prop.table(table(subset(demo, Group == 'hc')$Demo_Sex))["1"]*100, 1), '%')
demo_table["Age (SD)", "Clinical High-Risk (CHR)"] <- paste0(round(mean(subset(demo, Group == 'chr')$Demo_Age),1), " (", round(sd(subset(demo, Group == 'chr')$Demo_Age),1), ")")
demo_table["Age (SD)", "Healthy Controls (HC)"] <- paste0(round(mean(subset(demo, Group == 'hc')$Demo_Age),1), " (", round(sd(subset(demo, Group == 'hc')$Demo_Age),1), ")")

chr_race <- paste0(round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["8"]*100, 1), "% White; ",
                  round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["5"]*100, 1), "% Black; ",
                  round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["2"]*100 +
                          prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["3"]*100 +
                          prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["4"]*100, 1), "% Asian; ",
                  round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["6"]*100, 1), "% Central/South American; ",
                  round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["9"]*100, 1), "% Native Hawaiian or Pacific Islander; ",
                  round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["10 (1,8)"]*100,1) +
                          round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["10 (5,8)"]*100,1) +
                          round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["10 (7,8)"]*100,1) +
                          round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["10 (asian, 8)"]*100, 1), "% Multiracial (",
                  round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["10 (1,8)"]*100, 1), "% First Nations & White; ",
                  round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["10 (5,8)"]*100, 1), "% Black & White; ",
                  round(prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["10 (7,8)"]*100 +
                          prop.table(table(subset(demo, Group == 'chr')$Demo_Race))["10 (asian, 8)"]*100, 1), "% Asian & White)")

chr_ethnicity <- paste0(round(prop.table(table(subset(demo, Group == 'chr')$Demo_Hispanic))["1"]*100, 1), "% Hispanic; ",
                        round(prop.table(table(subset(demo, Group == 'chr')$Demo_Hispanic))["0"]*100, 1), "% Not Hispanic")

hc_race <- paste0(round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["8"]*100, 1), "% White; ",
                  round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["5"]*100, 1), "% Black; ",
                  round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["2"]*100 +
                          prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["3"]*100 +
                          prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["4"]*100 +
                          prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["7"]*100, 1), "% Asian; ",
                  round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["1"]*100, 1), "% First Nations; ",
                  round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10"]*100,1) +
                          round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10 (1,8)"]*100,1) +
                          round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10 (2, 8)"]*100,1) +
                          round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10 (4, 8)"]*100,1) +
                          round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10 (5,8)"]*100, 1), "% Multiracial (",
                  round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10 (1,8)"]*100, 1), "% First Nations & White; ",
                  round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10 (5,8)"]*100, 1), "% Black & White; ",
                  round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10 (2, 8)"]*100 +
                          prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10 (4, 8)"]*100, 1), "% Asian & White; ",
                  round(prop.table(table(subset(demo, Group == 'hc')$Demo_Race))["10"]*100, 1), "% not reported)")

hc_ethnicity <- paste0(round(prop.table(table(subset(demo, Group == 'hc')$Demo_Hispanic))["1"]*100, 1), "% Hispanic; ",
                        round(prop.table(table(subset(demo, Group == 'hc')$Demo_Hispanic))["0"]*100, 1), "% Not Hispanic")                 

chr_l1 <- paste0(round(100*table(subset(demo, Group == 'chr')$Demo_L1)["1"]/nrow(subset(demo, Group == 'chr')), 1), "% English; ",
                 round(100*table(subset(demo, Group == 'chr')$Demo_L1)["2"]/nrow(subset(demo, Group == 'chr')), 1), "% Other; ",
                 100-round(100*sum(table(subset(demo, Group == 'chr')$Demo_L1))/nrow(subset(demo, Group == 'chr')), 1), "% Not reported")

hc_l1 <- paste0(round(100*(table(subset(demo, Group == 'hc')$Demo_L1)["1"] + (table(subset(demo, Group == 'hc')$Demo_L1)["1,2"]))/nrow(subset(demo, Group == 'hc')), 1), "% English; ",
                 round(100*table(subset(demo, Group == 'hc')$Demo_L1)["2"]/nrow(subset(demo, Group == 'hc')), 1), "% Other; ",
                 100-round(100*sum(table(subset(demo, Group == 'hc')$Demo_L1))/nrow(subset(demo, Group == 'hc')), 1), "% Not reported")
                                                                                                                       
demo_table["Race", "Clinical High-Risk (CHR)"] <-  chr_race
demo_table["Race", "Healthy Controls (HC)"] <-  hc_race
demo_table["Ethnicity", "Clinical High-Risk (CHR)"] <-  chr_ethnicity
demo_table["Ethnicity", "Healthy Controls (HC)"] <-  hc_ethnicity
demo_table["First Language", "Clinical High-Risk (CHR)"] <-  chr_l1
demo_table["First Language", "Healthy Controls (HC)"] <-  hc_l1


apa_table(demo_table, caption = "(ref:demo-table-caption)")#, align = c("p{3.1cm}", "p{6.5cm}", "p{6.5cm}"))

```

## Speech tasks
Working one-on-one with an experimenter, participants provided three speech samples, recorded via a Zoom H2n portable recorder.

### Diadochokinetic Speech Task
Participants first completed a diadochokinetic speech task, commonly-used to examine speech motor abilities, in which they were asked to produce particular syllable types as quickly and accurately as possible.[@ackermann_oral_1995; @fletcher_time-by-count_1972] 
<!-- @canter_speech_1965; -->
They first produced 12 Alternating Motion Rate (AMR) trials, repeating a target syllable 15 times (two trials each of: pa-pa-pa..., ta-ta-ta..., ka-ka-ka..., ba-ba-ba..., da-da-da..., ga-ga-ga...). They then produced 20 Sequential Motion Rate (SMR) trials, producing sequences of three syllables 10 times each per trial (10 trials each of pa-ta-ka... and ka-ta-pa...).

### Read Speech Task: Rainbow Passage
Participants then read aloud the Rainbow Passage at a comfortable pace (passage in SM-1.1).[@fairbanks_voice_1960] The passage is commonly-used for eliciting read speech, as it is phonetically balanced (covering all English speech sounds) and emotionally neutral. The Rainbow Passage has quite a few low-frequency words (e.g., “Aristotle”, “refraction”), so it is relatively difficult to read. This speech task allows us to precisely control the speech content, while eliciting a more naturalistic speaking style than diadochokinetic speech.

### Spontaneous Procedural Description Task: Peanut Butter and Jelly
Finally, we elicited spontaneous speech, by asking participants to describe how to make a peanut butter and jelly sandwich for ~2 minutes. Unlike the other tasks, the speech content differed between participants (though many words overlapped: e.g., peanut, butter, knife). Such procedural description tasks are less emotionally and cognitively demanding than personal narratives while still generating a large volume of speech.[@fromm_pwas_2013]

## Speech Measures

At a high-level, for each participant, for each speech sample, we estimated how variable (i) their consonant productions, (ii) their vowel productions, (iii) their speech rates, and (iv) their pausing/timing were using semi-automated methods.[@adi_automatic_2016; @barreda_fast_2021; @mcauliffe_montreal_2017; @segal_ddktor_2022] Semi-automated methods greatly increase the amount of speech we can study, as extracting speech measures by-hand is extremely time-consuming, and ensure that our measurements are consistent and replicable (analysis code is available at github.com/khitczenko/chr_speech; the National Institute of Mental Health Data Archive provides de-identified clinical, risk, and demographic information). As a result, we focused on speech measures that have been extremely well-studied and can be reliably measured automatically. The main text focuses on (i) variability in the audible duration (voice-onset-time) of stop consonants (in English: p,t,k,b,d,g), (ii) variability in the duration of vowels, and (iii) variability in speech rates (calculated at the syllable level). We discuss the remaining speech measures we studied[@sichlinger_clinical_2019; @stanislawski_negative_2021; @hillenbrand_acoustic_1995; @mccloy_talker_2015; @xie_lifg_2018; @niziolek_assessing_2018] <!-- @wright_factors_2004; @peterson_control_1952; --> in Table \@ref(tab:speech-measures-table) and SM-1.3.

For the diadochokinetic speech samples, we used DDKtor[@segal_ddktor_2022] (https://github.com/MLSpeech/DDKtor) to automatically obtain the onset and offset (and thus, duration) of each stop consonant, vowel, and syllable given hand-selected windows of analysis which corresponded to the individual diadochokinetic trials. For the read and spontaneous speech, we first used the Montreal Forced Aligner to align a transcript we created for each speech sample to its audio. This provided us with the onset and offset (and thus, duration) of each vowel, consonant, and syllable produced. We then applied AutoVOT to the aligner output to obtain even more reliable onset and offsets for the stop consonants. We followed all recommendations provided by the creators of these tools (see SM-1.2 for full details).

We measure variability using coefficients of variation, which control for potential differences in means, calculated as follows[@whiteside_patterns_2003]:
$$\text{Coefficient of Variation} = \frac{\text{Standard Deviation}}{\text{Mean}}$$

All measures are log-transformed in the analyses (as they tend to be skewed right, due to lower bounds at 0).

### Variability in consonant duration
We focused on syllable-initial stop consonants (in English: p, t, k, b, d, g) that precede vowels (e.g., the bolded sounds in “**p**asser**b**y”, “**p**ulp”, “**p**eanut”, but not the “p” in “prism”), as they have easily-measurable acoustics.[@pascal_auzou_voice_2000; @lisker_cross-language_1964] In the diadochokinetic speech tasks, we restricted our analysis even further to only include voiceless stop consonants (in English: p, t, k), as the automated tool we use for this task has only been validated for this subset. 
<!-- We focused on stop consonants because their acoustics properties are extremely well-studied and can be measured automatically. -->
<!-- @abramson_voice_2017;  -->
We used the duration of the audible portion of each consonant (voice-onset-time)  to calculate: (i) the coefficient of variation over voiceless stop (p,t,k) consonants (all speech samples) and (ii) the coefficient of variation over voiced stop (b,d,g) consonants (read and spontaneous speech only).

### Variability in vowel duration
We focused on vowels that bear primary stress (e.g., only the bolded sounds: “**e**lement”, “aw**a**ken”, “an**a**lysis”) as they have easily-measurable acoustics. We used each relevant vowel’s duration to calculate the coefficient of variation across vowel tokens in each speech sample.

### Variability in speech rate
Speech rate was calculated as the number of syllables participants produced per second. For diadochokinetic speech, we calculated the speech rate of each individual trial and calculated the coefficient of variation across all trials produced. For read and spontaneous speech, we calculated the speech rate of delimited phrases, defined as any spoken interval between silences of at least 150ms.[@stuart-smith_private_2015] We then calculated the coefficient of variation across all produced phrases.

## Non-speech validation measures
We used symptom severity measures, non-speech motor measures, and risk measures to establish the clinical, convergent, and predictive validity of the speech measures.

### Clinical Utility: Symptomatology
We assessed symptom severity with SIPS scores.[@miller_symptom_1999] We focused particularly on the positive symptoms, negative symptoms, and disorganized symptoms totals to study how broadly clinically useful the speech measures are. In addition, we looked at the individual item G3 (“Motor Difficulties” - i.e., have you noticed any clumsiness, awkwardness, or lack of coordination in your movements?) to provide convergent validity of our speech measures as measuring motor difficulties.

### Convergent Validity: Finger-Tapping Scores
Participants also completed a computerized finger-tapping task, a well-established neuropsychological measure of motor deficits.[@gur_cognitive_2010; @saykin_normative_1995; @spencer_disrupted_2003; @carroll_timing_2009; @da_silva_more_2012; @damme_detecting_2020; @damme_sensorimotor_2021; @osborne_psychomotor_2020; @rund_neurocognition_2016] Participants are instructed to press the spacebar with their index finger as quickly as possible for 10s. They complete three trials per hand. Motivated by previous work[@damme_sensorimotor_2021; @dean_longitudinal_2020] and to parallel our speech measures, we study the coefficient of variation in number of taps across trials, calculated separately for the dominant and non-dominant hands.

### Predictive Validity: SIPS Risk Calculator
Finally, we use the SIPS-RC risk calculator[@zhang_prediction_2019] to calculate each participant’s risk of conversion to psychosis within one year (from SIPS and General Functioning scores[@niendam_neurocognitive_2006]). SIPS-RC scores can range from 0.4 to 46.9, but range from 0.8 to 10.1 in our sample.

## Adaptations to remote testing
Data collection occurred between 2019-2022, and our study had to be adapted to the remote format partway through due to the COVID-19 pandemic.

We adapted speech data collection, by mailing participants the same Zoom H2n recorders that had been used in the lab prior to the pandemic and having an experimenter administer the tasks over Zoom (tele-conferencing software). Similarly, all clinical interviews were conducted over Zoom beginning March 2020. Finally, the finger-tapping task, which, prior to March 2020, was collected in-lab as part of the Penn computerized neurocognitive battery[@moore_psychometric_2015] and included 5 trials per hand was adapted into a shortened, online version, where participants only completed 3 trials per hand. To equate these measures, only the first 3 trials from each in-person participant’s task were used.

<!-- While these changes were unavoidable, they may have impacted the reliability of the speech and finger-tapping measures. We provided extensive guidelines, but we had limited control over the participants’ environment (e.g., how noisy it was) and equipment (e.g., keyboard), and these factors may have introduced noise into our measures, reducing power.  -->
<!-- We return to this issue in the discussion. -->

## Analyses
We run separate analyses for each speech measure in each speech sample type.[@R-base; @R-papaja; @R-ggplot2; @R-dplyr; @R-ggpubr; @R-stringr] First, to test our prediction that CHR individuals exhibit more variability in their speech productions relative to controls, we run a logistic regression predicting group status (CHR vs. HC) from each speech measure (separately). For durational speech measures, we control for averaged speech rate, by including it as an additional predictor in the regression. Next, for each speech measure that significantly differentiates clinical status, we test its clinical/convergent/predictive validity, by running separate linear regressions predicting each validation measure from each speech measure, within the CHR group only.

**Data Availability**: All data used in this study are currently available by request from the corresponding author (K.H.). Upon acceptance, the speech measure data will be made available at github.com/khitczenko/chr_speech. The National Institute of Mental Health Data Archive provides the de-identified clinical, risk, and demographic information. All analysis code is available at github.com/khitczenko/chr_speech.

**Acknowledgments**: This work was supported by the National Institutes of Health (R21 MH119677 to M.G. and V.M.). Thank you to Emily Cibelli for assistance developing the speech protocol and to Cameron Martinez, Denise Zou, Solmi Park, Maksim Giljen, Gabrielle Olson, Juston Osborne, and Kate Damme for assistance in data collection/compilation.

\newpage

# References

<!-- ::: {#refs custom-style="Bibliography"} -->
<!-- ::: -->
